{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qK032BmIcGOk2PtEuLtCYXXb51RmcrJq",
      "authorship_tag": "ABX9TyPAWFx+/oLnVOSrYthpr9L3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZakNasz/Deep-Learning-in-Intelligent-Video-Analytics-and-Computer-Vision-5-day-workshop/blob/main/zakwan_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aSuZvav_VJ4V"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "xQxHqOgEVN_F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "# dataset = '/content/drive/My Drive/01. TEACHING/MACHINE_VISION/code/fruit_dataset'\n",
        "dataset = '/content/drive/MyDrive/fruit_dataset1'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train')\n",
        "test_directory = os.path.join(dataset, 'validation')\n",
        "\n",
        "# Batch size\n",
        "batchSize = 32\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "# print(idx_to_class)"
      ],
      "metadata": {
        "id": "KCsBTLA-VQRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb20f71-b429-4254-de4b-015d92eeb378"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']"
      ],
      "metadata": {
        "id": "gFJ8KVulVUp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1b8d21-01ea-4469-d1e3-b4685e33b0f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 840\n",
              "    Root location: /content/drive/MyDrive/fruit_dataset1/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               CenterCrop(size=(224, 224))\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "# valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_data_loader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
        "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
        "test_data_loader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
      ],
      "metadata": {
        "id": "gi5vepz-VWhV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_size, test_data_size"
      ],
      "metadata": {
        "id": "9b6V7G8AVYXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdda8be0-cc68-4e60-ebe9-745cd6b79054"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(840, 323)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (3,32,32)"
      ],
      "metadata": {
        "id": "-Dsw8GPxVZxp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#                  Create Dataloader                     #\n",
        "#######################################################\n",
        "\n",
        "# Turn train and test custom Dataset's into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "trainloader = DataLoader(dataset=data['train'], # use custom created train Dataset\n",
        "                                     batch_size=4, # how many samples per batch?\n",
        "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
        "                                     shuffle=True) # shuffle the data?\n",
        "\n",
        "testloader = DataLoader(dataset=data['test'], # use custom created test Dataset\n",
        "                                    batch_size=4, \n",
        "                                    num_workers=0, \n",
        "                                    shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_data_size = len(trainloader.dataset)\n",
        "test_data_size = len(testloader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ],
      "metadata": {
        "id": "WY-kwu_vVbEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d458c330-7657-4279-c3af-d3ea53d5fd1e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "840\n",
            "323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "# DEFINE YOUR OWN MODEL\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "print(model)\n",
        "model.eval()\n",
        "\n",
        "num_ftrs = model.fc.in_features \n",
        "# Here the size of each output sample is set to 10.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.eval = nn.Linear(num_ftrs, 4)\n",
        "\n",
        "\n",
        "\n",
        "#######################\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "qW9LfTN7VcaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13041827-dac2-4b50-bd79-e563bdbdd6ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  (eval): Linear(in_features=2048, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "VwW5L_78VeR-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the model for 10 epochs\n",
        " \n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "RWPuWDkdVf9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc6c559-e932-423f-ed42-c0c40cb24645"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 2.4381, Accuracy: 36.0714%, \n",
            "\t\tValidation : Loss : 0.9408, Accuracy: 60.0619%, Time: 326.9094s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 1.3790, Accuracy: 45.9524%, \n",
            "\t\tValidation : Loss : 0.8057, Accuracy: 65.3251%, Time: 16.6962s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 1.2108, Accuracy: 50.7143%, \n",
            "\t\tValidation : Loss : 0.9937, Accuracy: 54.4892%, Time: 16.5576s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 1.1251, Accuracy: 53.3333%, \n",
            "\t\tValidation : Loss : 0.8820, Accuracy: 65.9443%, Time: 16.4283s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 1.1702, Accuracy: 50.1190%, \n",
            "\t\tValidation : Loss : 0.8194, Accuracy: 65.9443%, Time: 16.5879s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 1.0905, Accuracy: 55.2381%, \n",
            "\t\tValidation : Loss : 0.7109, Accuracy: 68.4211%, Time: 16.6874s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 1.0719, Accuracy: 56.7857%, \n",
            "\t\tValidation : Loss : 0.7485, Accuracy: 73.9938%, Time: 16.7479s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.9505, Accuracy: 60.5952%, \n",
            "\t\tValidation : Loss : 1.0292, Accuracy: 70.5882%, Time: 16.7324s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.9042, Accuracy: 63.5714%, \n",
            "\t\tValidation : Loss : 0.8702, Accuracy: 69.0402%, Time: 16.5976s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.8909, Accuracy: 61.3095%, \n",
            "\t\tValidation : Loss : 1.1277, Accuracy: 59.7523%, Time: 16.5551s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Analyze the loss curve\n",
        "\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "# plt.savefig('cifar10_loss_curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qf70mL57VhpI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ca860864-665e-4dcd-ae3d-c8f7f81f42ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Analyze the accuracy curve\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "# plt.savefig('cifar10_accuracy_curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Akou3-WtVjFZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b270ac76-05f9-49a2-9377-541e0757ddb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference on webcam"
      ],
      "metadata": {
        "id": "KFEbG4gu0DVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "IvzaiGev0F1W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "IfcR6acO0Ii4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    #     rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Apply transforms to the input image.\n",
        "    input_tensor = transform(frame)\n",
        "    # Add the batch dimension.\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    input_batch = input_batch.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        output = model(input_batch)\n",
        "        end_time = time.time()\n",
        "    # Get the softmax probabilities.\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    # Check the top 5 categories that are predicted.\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "    \n",
        "    cv2.putText(frame, f\"{top5_prob[0].item()*100:.3f}%\", (15, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, f\"{categories[top5_catid[0]]}\", (160, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    print(categories[top5_catid[0]], top5_prob[0].item())\n",
        "    cv2_imshow(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "v4LFmPSi0LBn",
        "outputId": "9329694e-536d-4727-9248-2d2eff78221c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-290a478f976a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#     rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Apply transforms to the input image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Add the batch dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
          ]
        }
      ]
    }
  ]
}